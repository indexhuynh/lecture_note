\input{library}
\input{config}
\newcommand{\tab}{\hspace{\parindent}}
%-------------------------------------------------------------------------------
\begin{document}
\begin{titlepage}
\bordertitle
\begin{center}
\vspace{\fill} \maintitle \\ \vspace{\fill} \bottitle
\end{center}
\end{titlepage}
%-------------------------------------------------------------------------------
\newpage
\newgeometry{left=3cm,right=2cm,top=1cm,bottom=2cm}
\tableofcontents
\thispagestyle{empty}
%-------------------------------------------------------------------------------
\newpage
\chapter*{ Preface }
\thispagestyle{empty}
%-------------------------------------------------------------------------------
\vspace{\fill}

\vspace{\fill}
%-------------------------------------------------------------------------------
\newpage
\setcounter{page}{1}
\chapter{ Introduction }
%-------------------------------------------------------------------------------
\section{ Syllabus }
\begin{itemize}
    \item\textbf{Prerequisites:} Discrete mathematics, statistical mathematics.
    \item \textbf{Topics Covered:} Big data foundation, models, processing
        tools.
    \item \textbf{Self-Taught Content}: Corporate culture.
    \item \textbf{Programming language:} Python
\end{itemize}
\section{ Objective }
    The objective of this course is to enable students to understand and 
    articulate fundamental concepts related to big data. Students will learn to 
    organize and store data using big data storage platforms, and will apply 
    data mining, machine learning, and AI algorithms to practical tasks. 
    Furthermore, students will be able to research and understand the systems 
    and ecosystems of a chosen company.
\section{ Course Content }
\begin{itemize}
    \item \textbf{Overview}: The course begins with an \textbf{overview of big
        data}, focusing on the reasons for studying this topic.
    \item \textbf{MapReduce Model:} Students will learn about the 
        \textbf{MapReduce model}, which is the foundational model and a 
        prerequisite for further development in the field.
    \item \textbf{Apache Spark Framework}: This section covers \textbf{Apache
        Spark}, where students will acquire foundational knowledge of this
        essential big data processing tool.
    \item \textbf{Big Data Ecosystem}: The course concludes with a study of the
        \textbf{big data ecosystem}, which serves as both the final project and
        a seminar topic.
\end{itemize}
%-------------------------------------------------------------------------------
\chapter{ Overview }
\section{ Introduction }
\subsection{ Scenario }
    With the Samsung ecosystem, all activities are synchronized, helping users
    save a lot of time. This is achieved by applying numerous big data
    technologies. Some key examples include: parallel computing, massive data
    storage, data distribution, high-speed network connectivity,
    high-performance computing, task and workflow management, data analysis and
    mining, data collection, machine learning, and data visualization. These
    thechnologies are foundational and, in some ways, quite mature, which shows
    that learning cannot always keep pace with society's rapid development. The
    more details you can uncover.
%-------------------------------------------------------------------------------
\section{ Definition }
    Big Data is an information asset characterized by high-volume, 
    high-velocity, and high-variety data. It requires new technologies to be
    processed in order to enable effective decision-making, discover hidden
    insights, and optimize data processing.
%-------------------------------------------------------------------------------
\section{ Big data processing workflow }
    Big data processing workflow is a critical sequence of steps that includes
    \textbf{collection}, \textbf{storage}, and \textbf{analysis}.
    \begin{itemize}
        \item \textbf{Data Collection}: In this initial phase, data is gathered    
            from two main sources: \textbf{active} (using tools like web
            crawlers) and \textbf{passive} (from sources such as surveilliance
            video and clickstreams). The collected data is then transported to
            storage locations via high-speed connections, where it is
            integrated, cleaned, and de-duuplicated to ensure quality.
        \item \textbf{Data Storage}: For storage, it is essential to evaluate
            the infrastructure and budget to decide between \textbf{SSD} or
            \textbf{HDD} and to segment the data into smaller parts. To enable
            communication between these parts, selecting an appropriate network
            architecture (such as \textbf{DAS}, \textbf{NAS}, or \textbf{SAN})
            is crucial. Next, a suitable database management system must be
            chosen (e.g., \textbf{HDFS}, \textbf{key-value}, column-oriented,
            or document-oriented databases). For efficient storage, programming
            models like \textbf{MapReduce}, \textbf{stream processing}, or
            \textbf{graph processing} are utilized based on specific
            objectives.
        \item \textbf{Data Analysis}: The final step is analysis. First, the
            specific problem and goals must be clearly defined. There is a
            wide range of analytical methods available, including
            \textbf{statistical analysis}, \textbf{data mining},
            \textbf{text mining}, \textbf{network and graph data mining},
            \textbf{clustering}, \textbf{classification and regression}, and
            \textbf{association analysis}. Each diverse field requires its
            own customized analytical techniques.
    \end{itemize}
%-------------------------------------------------------------------------------

%-------------------------------------------------------------------------------
\end{document}
